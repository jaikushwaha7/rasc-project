{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASC: Relationship-Aware Scene Captioning\n",
    "## Google Colab Training Notebook\n",
    "\n",
    "This notebook trains the complete RASC pipeline on Google Colab:\n",
    "1. **Object Detection** (YOLOv8)\n",
    "2. **Relationship Prediction** (Neural Motifs)\n",
    "3. **Caption Generation** (T5)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install -q ultralytics transformers datasets PyYAML pillow tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive (to save models and access data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone or upload the RASC project\n",
    "# Option 1: Clone from GitHub\n",
    "# !git clone https://github.com/yourusername/rasc.git /content/rasc\n",
    "\n",
    "# Option 2: Upload the zip file and extract\n",
    "!mkdir -p /content/rasc\n",
    "# Upload rasc-project.zip using the file browser, then:\n",
    "# !unzip -q /content/rasc-project.zip -d /content/\n",
    "\n",
    "# Option 3: Copy from Google Drive\n",
    "# !cp -r /content/drive/MyDrive/rasc-project /content/rasc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/rasc/src')\n",
    "\n",
    "# Verify setup\n",
    "!ls -la /content/rasc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Upload Processed Data\n",
    "\n",
    "Since you already have processed data locally, upload it to Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Option 1: Upload from local machine\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your processed data files:\")\n",
    "print(\"1. vg_5k_subset.json\")\n",
    "print(\"2. label_map.json\")\n",
    "print(\"3. relationship_pairs.json\")\n",
    "print(\"4. Train/val/test splits (zip them first)\")\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Option 2: Copy from Google Drive (faster for large files)\n",
    "# Assuming you've uploaded data to Drive beforehand:\n",
    "!mkdir -p /content/rasc/data/processed/relationships\n",
    "!mkdir -p /content/rasc/data/splits\n",
    "\n",
    "# Copy processed files\n",
    "!cp /content/drive/MyDrive/rasc_data/vg_5k_subset.json /content/rasc/data/processed/\n",
    "!cp /content/drive/MyDrive/rasc_data/label_map.json /content/rasc/data/processed/\n",
    "!cp /content/drive/MyDrive/rasc_data/relationship_pairs.json /content/rasc/data/processed/relationships/\n",
    "\n",
    "# Copy splits\n",
    "!cp -r /content/drive/MyDrive/rasc_data/splits/* /content/rasc/data/splits/\n",
    "\n",
    "# Verify\n",
    "!ls -lh /content/rasc/data/processed/\n",
    "!ls -lh /content/rasc/data/splits/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Create Colab-optimized configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import yaml\n",
    "\n",
    "# Detect device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create Colab config\n",
    "config = {\n",
    "    'project': {'name': 'rasc', 'version': '1.0.0', 'seed': 42},\n",
    "    'paths': {\n",
    "        'processed_data': '/content/rasc/data/processed',\n",
    "        'models': '/content/rasc/models',\n",
    "        'experiments': '/content/rasc/experiments/runs',\n",
    "        'logs': '/content/rasc/logs',\n",
    "        'label_map': '/content/rasc/data/processed/label_map.json',\n",
    "        'relationship_pairs': '/content/rasc/data/processed/relationships/relationship_pairs.json',\n",
    "        'splits': '/content/rasc/data/splits'\n",
    "    },\n",
    "    'detection': {\n",
    "        'model_name': 'yolov8n',\n",
    "        'training': {\n",
    "            'epochs': 30,\n",
    "            'batch_size': 16,\n",
    "            'image_size': [512, 640],\n",
    "            'workers': 2,\n",
    "            'device': device\n",
    "        },\n",
    "        'optimizer': {'lr0': 0.01}\n",
    "    },\n",
    "    'relationship': {\n",
    "        'model_type': 'neural_motifs',\n",
    "        'num_classes': 150,\n",
    "        'num_relations': 10,\n",
    "        'embedding_dim': 128,\n",
    "        'training': {\n",
    "            'epochs': 15,\n",
    "            'batch_size': 64,\n",
    "            'learning_rate': 0.001\n",
    "        }\n",
    "    },\n",
    "    'captioning': {\n",
    "        'model_name': 't5-small',\n",
    "        'training': {\n",
    "            'epochs': 5,\n",
    "            'batch_size': 8,\n",
    "            'learning_rate': 0.0001\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "!mkdir -p /content/rasc/configs\n",
    "with open('/content/rasc/configs/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úì Configuration created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Stage 1: Object Detection Training\n",
    "\n",
    "Train YOLOv8 for object detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# First, create YOLO config file\n",
    "yolo_config = \"\"\"\n",
    "path: /content/rasc/data/splits\n",
    "\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 150\n",
    "names: ['window', 'man', 'tree', 'wall', 'shirt', 'building', 'person', 'ground', 'sky', 'sign']\n",
    "# ... add all 150 class names from your label_map.json\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/rasc/configs/yolo.yaml', 'w') as f:\n",
    "    f.write(yolo_config)\n",
    "\n",
    "# Load actual class names from label_map\n",
    "import json\n",
    "with open('/content/rasc/data/processed/label_map.json') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# Sort by index and create names list\n",
    "names = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]\n",
    "print(f\"Loaded {len(names)} object classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train YOLO\n",
    "%cd /content/rasc\n",
    "!python src/models/train_yolo.py \\\n",
    "  --config configs/config.yaml \\\n",
    "  --experiment-name yolo_colab_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Monitor training (in separate cell while training)\n",
    "# View logs\n",
    "!tail -n 20 /content/rasc/logs/*.log\n",
    "\n",
    "# Check experiments\n",
    "!ls -lh /content/rasc/experiments/runs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Stage 2: Relationship Prediction Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train relationship model\n",
    "!python src/models/train_relationship.py \\\n",
    "  --config configs/config.yaml \\\n",
    "  --experiment-name relationship_colab_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check training progress\n",
    "import json\n",
    "\n",
    "# Find latest experiment\n",
    "import glob\n",
    "exp_dirs = glob.glob('/content/rasc/experiments/runs/relationship_*')\n",
    "latest_exp = sorted(exp_dirs)[-1]\n",
    "\n",
    "# Load metrics\n",
    "metrics_file = f\"{latest_exp}/metrics/metrics.json\"\n",
    "if os.path.exists(metrics_file):\n",
    "    with open(metrics_file) as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    # Plot training curve\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if 'train_loss' in metrics:\n",
    "        train_loss = [m['value'] for m in metrics['train_loss']]\n",
    "        plt.plot(train_loss, label='Train Loss')\n",
    "        \n",
    "    if 'val_loss' in metrics:\n",
    "        val_loss = [m['value'] for m in metrics['val_loss']]\n",
    "        plt.plot(val_loss, label='Val Loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Relationship Model Training')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Stage 3: Caption Generation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# First, build T5 dataset from relationships\n",
    "# You'll need to create this file or copy it\n",
    "!python src/data/build_t5_dataset.py --config configs/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train T5 caption model\n",
    "!python src/models/train_t5.py \\\n",
    "  --config configs/config.yaml \\\n",
    "  --experiment-name t5_colab_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Inference & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload a test image\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "print(\"Upload a test image:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the filename\n",
    "test_image = list(uploaded.keys())[0]\n",
    "\n",
    "# Display image\n",
    "img = Image.open(io.BytesIO(uploaded[test_image]))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Test Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run inference\n",
    "!python src/models/inference.py \\\n",
    "  --image {test_image} \\\n",
    "  --config configs/config.yaml \\\n",
    "  --output results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# View results\n",
    "with open('results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INFERENCE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nObjects detected: {results['num_objects']}\")\n",
    "print(f\"Relationships: {results['num_relationships']}\")\n",
    "print(f\"\\nGenerated Caption:\")\n",
    "print(f\"  {results['caption']}\")\n",
    "print(f\"\\nInference time: {results['inference_time']:.2f}s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Models to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save trained models to Google Drive for persistence\n",
    "!mkdir -p /content/drive/MyDrive/rasc_models\n",
    "\n",
    "# Copy YOLO weights\n",
    "!cp -r /content/rasc/experiments/runs/yolo_colab_v1*/weights \\\n",
    "  /content/drive/MyDrive/rasc_models/yolo_weights\n",
    "\n",
    "# Copy relationship model\n",
    "!cp /content/rasc/models/relationship_predictor/*.pt \\\n",
    "  /content/drive/MyDrive/rasc_models/\n",
    "\n",
    "# Copy T5 model\n",
    "!cp -r /content/rasc/models/caption_generator/t5_scene \\\n",
    "  /content/drive/MyDrive/rasc_models/\n",
    "\n",
    "print(\"‚úì Models saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä View Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List all experiments\n",
    "!ls -lh /content/rasc/experiments/runs/\n",
    "\n",
    "# View metrics for a specific experiment\n",
    "exp_name = \"yolo_colab_v1_20240210_143022\"  # Replace with your experiment\n",
    "!cat /content/rasc/experiments/runs/{exp_name}/metrics/metrics.json | python -m json.tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize detection results\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load best YOLO model\n",
    "model = YOLO('/content/rasc/experiments/runs/yolo_colab_v1_*/weights/best.pt')\n",
    "\n",
    "# Run on test image\n",
    "results = model(test_image)\n",
    "\n",
    "# Display\n",
    "results[0].plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
